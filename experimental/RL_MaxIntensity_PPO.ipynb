{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\joewa\\\\Work\\\\git\\\\vimms')\n",
    "sys.path.append('C:\\\\Users\\\\Vinny\\\\work\\\\vimms')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random as rand\n",
    "import pylab as plt\n",
    "import multiprocessing\n",
    "from gym import spaces\n",
    "\n",
    "from stable_baselines3 import DQN, PPO, A2C\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vimms.Common import *\n",
    "from vimms.Gym import VimmsGymEnv\n",
    "from vimms.Evaluation import evaluate_simulated_env, evaluate_multiple_simulated_env\n",
    "from vimms.ChemicalSamplers import MZMLFormulaSampler, MZMLRTandIntensitySampler\n",
    "from vimms.Controller import SimpleTargetController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "rand.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_log_level_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_chemicals = (200, 500)\n",
    "# mz_range = (100, 600)\n",
    "# rt_range = (0, 300)\n",
    "# intensity_range = (1E5, 1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_chemicals = (500, 2000)\n",
    "# mz_range = (100, 600)\n",
    "# rt_range = (200, 1000)\n",
    "# intensity_range = (1E5, 1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n_chemicals = (200, 500)\n",
    "mz_range = (100, 600)\n",
    "rt_range = (200, 1000)\n",
    "intensity_range = (1E5, 1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "min_mz = mz_range[0]\n",
    "max_mz = mz_range[1]\n",
    "min_rt = rt_range[0]\n",
    "max_rt = rt_range[1]\n",
    "min_log_intensity = np.log(intensity_range[0])\n",
    "max_log_intensity = np.log(intensity_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isolation_window = 0.7\n",
    "N = 10\n",
    "rt_tol = 15\n",
    "mz_tol = 10\n",
    "min_ms1_intensity = 5000\n",
    "ionisation_mode = POSITIVE\n",
    "noise_density = 0.3\n",
    "noise_max_val = 1e4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_dim = 50\n",
    "out_dim = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Custom gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mzml_filename = 'Beer_multibeers_1_fullscan1.mzML'\n",
    "mz_sampler = MZMLFormulaSampler(mzml_filename, min_mz=min_mz, max_mz=max_mz)\n",
    "ri_sampler = MZMLRTandIntensitySampler(mzml_filename, min_rt=min_rt, max_rt=max_rt,\n",
    "                                       min_log_intensity=min_log_intensity,\n",
    "                                       max_log_intensity=max_log_intensity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'chemical_creator': {\n",
    "        'mz_range': mz_range,\n",
    "        'rt_range': rt_range,\n",
    "        'intensity_range': intensity_range,\n",
    "        'n_chemicals': n_chemicals,\n",
    "        'mz_sampler': mz_sampler,\n",
    "        'ri_sampler': ri_sampler,\n",
    "    },\n",
    "    'noise': {\n",
    "        'noise_density': noise_density,\n",
    "        'noise_max_val': noise_max_val,\n",
    "        'mz_range': mz_range\n",
    "    },\n",
    "    'env': {\n",
    "        'ionisation_mode': ionisation_mode,\n",
    "        'rt_range': rt_range,\n",
    "        'N': N,\n",
    "        'isolation_window': isolation_window,\n",
    "        'mz_tol': mz_tol,\n",
    "        'rt_tol': rt_tol,\n",
    "        'min_ms1_intensity': min_ms1_intensity\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MaxIntensityEnv(VimmsGymEnv):\n",
    "    def __init__(self, in_dim, out_dim, params):\n",
    "        super().__init__(in_dim, out_dim, params)  \n",
    "        self.last_excluded = []\n",
    "        self.selected_precursors = []\n",
    "    \n",
    "    def _get_action_space(self):\n",
    "        \"\"\"\n",
    "        Defines action space\n",
    "        \"\"\"\n",
    "        return spaces.MultiBinary(self.out_dim)\n",
    "\n",
    "    def _get_observation_space(self):\n",
    "        \"\"\"\n",
    "        Defines observation space\n",
    "        \"\"\"\n",
    "        intensity_high = np.log(intensity_range[1]) + 10\n",
    "        features = {\n",
    "            'intensity': spaces.Box(low=0.0, high=intensity_high, shape=(self.in_dim,)),\n",
    "            'exclusion': spaces.Box(low=0.0, high=1.0, shape=(self.in_dim,))\n",
    "        }\n",
    "        return spaces.Dict(features)\n",
    "    \n",
    "    def _get_state(self, scan_to_process):\n",
    "        \"\"\"\n",
    "        Converts a scan to a state\n",
    "        \"\"\"\n",
    "        self.last_scan_to_process = scan_to_process        \n",
    "        mzs, rt, intensities = self._get_mzs_rt_intensities(scan_to_process)\n",
    "        \n",
    "        precursors = []\n",
    "        self.last_excluded = []\n",
    "        for mz, intensity in zip(mzs, intensities):\n",
    "            if self.controller.exclusion.is_excluded(mz, rt):\n",
    "                excluded = 0\n",
    "                self.last_excluded.append((mz, rt, intensity, ))                \n",
    "            else:\n",
    "                excluded = 1\n",
    "            precursor = (mz, intensity, excluded, )\n",
    "            precursors.append(precursor)                \n",
    "        \n",
    "        sorted_precursors = sorted(precursors, key=lambda item: item[1], reverse=True) # sort by intensity descending\n",
    "        self.selected_precursors = []        \n",
    "        feature_intensity = []\n",
    "        feature_exclusion = []\n",
    "        for i in range(self.in_dim): # get the first in_dim items\n",
    "            precursor = sorted_precursors[i]\n",
    "            mz, intensity, excluded = precursor            \n",
    "            self.selected_precursors.append(precursor)\n",
    "            \n",
    "            intensity = np.log(intensity)\n",
    "            if np.isnan(intensity):\n",
    "                intensity = 0\n",
    "            feature_intensity.append(intensity)\n",
    "            feature_exclusion.append(excluded)\n",
    "            \n",
    "        feature_intensity = np.array(feature_intensity)\n",
    "        feature_exclusion = np.array(feature_exclusion)\n",
    "        features = {\n",
    "            'intensity': feature_intensity,\n",
    "            'exclusion': feature_exclusion\n",
    "        }\n",
    "        return features\n",
    "    \n",
    "    def _compute_reward(self, scan_to_process, results):\n",
    "        \"\"\"\n",
    "        Computes fragmentation reward\n",
    "        \"\"\"\n",
    "        parent_scan_id = self.controller.last_ms1_scan.scan_id\n",
    "        assert scan_to_process.scan_id == parent_scan_id\n",
    "    \n",
    "        total_reward = 0.0\n",
    "        for last_scan in results:\n",
    "            if last_scan.ms_level >= 2:                \n",
    "                precursor = last_scan.scan_params.get(ScanParameters.PRECURSOR_MZ)[0]\n",
    "                mz = precursor.precursor_mz\n",
    "                frag_rt = last_scan.scan_params.get(ScanParameters.METADATA)['frag_at']\n",
    "                intensity = precursor.precursor_intensity\n",
    "                \n",
    "                # intensity reward\n",
    "                min_intensity = self.controller.min_ms1_intensity\n",
    "                reward = np.log(intensity) - np.log(min_ms1_intensity)\n",
    "                \n",
    "                # time reward\n",
    "                time_filter = -1 if (mz, frag_rt, intensity, ) in self.last_excluded else 1\n",
    "                reward = reward * time_filter\n",
    "                \n",
    "                total_reward += reward\n",
    "        \n",
    "        # use fewer fragmentations\n",
    "        if len(results) > 0:\n",
    "            total_reward /= len(results)\n",
    "        return total_reward    \n",
    "\n",
    "    def _take_action(self, action):\n",
    "        \"\"\"\n",
    "        Modify controller variables based on the selected action\n",
    "        \"\"\"\n",
    "        target_flag = action      \n",
    "        assert len(target_flag) == len(self.selected_precursors)\n",
    "        \n",
    "        targets = []\n",
    "        for i in range(len(target_flag)):\n",
    "            t = target_flag[i]\n",
    "            if t == 1:\n",
    "                mz, intensity, excluded = self.selected_precursors[i]\n",
    "                targets.append((mz, intensity))\n",
    "                \n",
    "        # self.seen_actions.update(['targets=%s' % targets])\n",
    "        self.controller.targets = targets\n",
    "        \n",
    "    def _reset_controller(self, env_params):\n",
    "        \"\"\"\n",
    "        Generates new controller\n",
    "        \"\"\"\n",
    "        ionisation_mode = env_params['ionisation_mode']\n",
    "        N = env_params['N']\n",
    "        isolation_window = env_params['isolation_window']\n",
    "        mz_tol = env_params['mz_tol']\n",
    "        rt_tol = env_params['rt_tol']\n",
    "        min_ms1_intensity = env_params['min_ms1_intensity']\n",
    "        controller = SimpleTargetController(ionisation_mode, N, isolation_window, mz_tol, rt_tol, min_ms1_intensity)\n",
    "        return controller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_log_level_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MaxIntensityEnv(in_dim, out_dim, params)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "def make_env(rank, seed=0):\n",
    "    def _init():\n",
    "        env = MaxIntensityEnv(in_dim, out_dim, params)\n",
    "        env.seed(rank)\n",
    "        return env\n",
    "    set_random_seed(seed)\n",
    "    return _init\n",
    "\n",
    "num_cpu = multiprocessing.cpu_count()\n",
    "num_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SubprocVecEnv([make_env(i) for i in range(num_cpu)]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = 'PPO'\n",
    "model = PPO(\"MultiInputPolicy\", env, verbose=1, tensorboard_log='./results/%s_MaxIntensityEnv_tensorboard' % model_name)\n",
    "model.learn(total_timesteps=250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'results/%s_maxintensity_smallchems' % model_name\n",
    "model.save(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load previously trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'PPO'\n",
    "fname = 'results/%s_maxintensity_smallchems' % model_name\n",
    "model = PPO.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_episodes = 20\n",
    "write_mzml_every = 5\n",
    "N = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate some evaluation chemicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chems_list = []\n",
    "for i in range(num_episodes):\n",
    "    env = MaxIntensityEnv(in_dim, out_dim, params)\n",
    "    env.reset()\n",
    "    chems = env.chems\n",
    "    print(len(chems))\n",
    "    chems_list.append(chems)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do a few topN steps manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topN(observation, N=10, min_ms1_intensity=5000):\n",
    "    intensities = observation['intensity']\n",
    "    exclusions = observation['exclusion']\n",
    "    log_min_ms1_intensity = np.log(min_ms1_intensity)\n",
    "    \n",
    "    action = []\n",
    "    count = 0\n",
    "    for i in range(len(intensities)):\n",
    "        intensity, exclusion = intensities[i], exclusions[i]\n",
    "        if count < N:\n",
    "            if exclusion == 1 and intensity > log_min_ms1_intensity:\n",
    "                action.append(1)\n",
    "                count += 1\n",
    "            else:\n",
    "                action.append(0)\n",
    "        else:\n",
    "            action.append(0)\n",
    "    action = np.array(action)\n",
    "    return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MaxIntensityEnv(in_dim, out_dim, params)\n",
    "chems = chems_list[0]\n",
    "observation = env.reset(chems=chems)\n",
    "observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    action = topN(observation, N=N, min_ms1_intensity=min_ms1_intensity)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    action, reward, observation, done\n",
    "    print('step %d' % i)\n",
    "    print('action = %s' % action)\n",
    "    print('reward = %f' % reward)\n",
    "    print('done = %s' % done)    \n",
    "    print('next observation = %s' % observation)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute evaluation here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluation(model, model_name, in_dim, out_dim, params, num_episodes, chems_list):\n",
    "    env = MaxIntensityEnv(in_dim, out_dim, params)\n",
    "    total_rewards = []\n",
    "    total_reward_per_chems = []\n",
    "    env_list = []\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        chems = chems_list[i_episode]\n",
    "        observation = env.reset(chems=chems)\n",
    "        total_reward = 0\n",
    "        for t in range(1000):\n",
    "            # env.render()\n",
    "            if model_name == 'random':\n",
    "                action = env.action_space.sample()\n",
    "                out_file = 'test_%s_%d.mzML' % ('random', i_episode)\n",
    "            elif model_name == 'TopN':\n",
    "                action = topN(observation, N=N, min_ms1_intensity=min_ms1_intensity)\n",
    "                out_file = 'test_%s_%d.mzML' % ('TopN', i_episode)                \n",
    "            else:\n",
    "                action, _ = model.predict(observation, deterministic=True)     \n",
    "                out_file = 'test_%s_%d.mzML' % (model_name, i_episode)\n",
    "                                                \n",
    "            observation, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                seen_actions = env.seen_actions.most_common()\n",
    "                n_chems = len(env.chems)\n",
    "                reward_per_chems = total_reward / n_chems\n",
    "                total_rewards.append(total_reward)\n",
    "                total_reward_per_chems.append(reward_per_chems)\n",
    "                env_list.append(env.vimms_env)\n",
    "                if i_episode % write_mzml_every == 0 or i_episode == num_episodes-1:\n",
    "                    env.vimms_env.write_mzML('results', out_file)\n",
    "                print('Episode %d timesteps %d reward %f n_chems %d reward/chems %f' % (i_episode, t+1, total_reward, n_chems, reward_per_chems))                                        \n",
    "                break\n",
    "    env.close()\n",
    "    print('Average total reward = %f' % np.mean(total_rewards))\n",
    "    return np.array(total_rewards), np.array(total_reward_per_chems), env_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_total_rewards, model_reward_per_chems, model_env_list = evaluation(model, model_name, in_dim, out_dim, params, num_episodes, chems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "topN_total_rewards, topN_reward_per_chems, topN_env_list = evaluation(None, 'TopN', in_dim, out_dim, params, num_episodes, chems_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_total_rewards, random_reward_per_chems, random_env_list = evaluation(None, 'random', in_dim, out_dim, params, num_episodes, chems_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_diff(controller_names, scores_list, ref_name, ref_scores):\n",
    "    for controller_name, scores in zip(controller_names, scores_list):\n",
    "        diff = scores - ref_scores\n",
    "        perc = np.multiply(diff, 1/ref_scores) * 100\n",
    "        plt.plot(diff, label=controller_name)\n",
    "    plt.title('Score improvement over %s' % ref_name)\n",
    "    plt.ylabel('Score Improvement (%)')\n",
    "    plt.xlabel('Episode')        \n",
    "    plt.legend()\n",
    "\n",
    "def plot_arr(controller_names, arr_list, title):\n",
    "    for controller_name, arr in zip(controller_names, arr_list):\n",
    "        plt.plot(arr, label=controller_name)\n",
    "    plt.title('%s per Episode' % title)\n",
    "    plt.ylabel(title)\n",
    "    plt.xlabel('Episode')        \n",
    "    plt.legend()\n",
    "        \n",
    "def get_scores(env_list, type='both'):\n",
    "    scores = []\n",
    "    for env in env_list:\n",
    "        score = get_score(env, type=type)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "def get_score(env, type='both'):\n",
    "    res = evaluate_simulated_env(env)\n",
    "    if type == 'both':\n",
    "        score = res['coverage_proportion'] * res['intensity_proportion']\n",
    "    elif type == 'coverage':\n",
    "        score = res['coverage_proportion']    \n",
    "    elif type == 'intensity':\n",
    "        score = res['intensity_proportion']    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_arr([model_name, 'TopN', 'Random'], [model_total_rewards, topN_total_rewards, random_total_rewards], 'Total Rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_arr([model_name, 'TopN', 'Random'], [model_reward_per_chems, topN_reward_per_chems, random_reward_per_chems], 'Reward/Chems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_type = 'coverage'\n",
    "model_scores = get_scores(model_env_list, type=score_type)\n",
    "topN_scores = get_scores(topN_env_list, type=score_type)\n",
    "random_scores = get_scores(random_env_list, type=score_type)\n",
    "plot_arr([model_name, 'TopN', 'Random'], [model_scores, topN_scores, random_scores], 'Scores (coverage)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_type = 'intensity'\n",
    "model_scores = get_scores(model_env_list, type=score_type)\n",
    "topN_scores = get_scores(topN_env_list, type=score_type)\n",
    "random_scores = get_scores(random_env_list, type=score_type)\n",
    "plot_arr([model_name, 'TopN', 'Random'], [model_scores, topN_scores, random_scores], 'Scores (intensity)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
