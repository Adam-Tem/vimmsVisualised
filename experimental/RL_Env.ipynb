{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\joewa\\\\Work\\\\git\\\\vimms')\n",
    "sys.path.append('C:\\\\Users\\\\Vinny\\\\work\\\\vimms')\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random as rand\n",
    "import pylab as plt\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vimms.Common import *\n",
    "from vimms.Gym import FragmentEnv\n",
    "from vimms.Evaluation import evaluate_simulated_env, evaluate_multiple_simulated_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "rand.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level_warning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chemicals = (400, 1000)\n",
    "mz_range = (100, 600)\n",
    "rt_range = (0, 500)\n",
    "intensity_range = (1E5, 1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_chemicals = (200, 500)\n",
    "# mz_range = (100, 600)\n",
    "# rt_range = (0, 300)\n",
    "# intensity_range = (1E5, 1E10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_mz = mz_range[0]\n",
    "max_mz = mz_range[1]\n",
    "min_rt = rt_range[0]\n",
    "max_rt = rt_range[1]\n",
    "min_log_intensity = np.log(intensity_range[0])\n",
    "max_log_intensity = np.log(intensity_range[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isolation_window = 0.7\n",
    "N = 10\n",
    "rt_tol = 15\n",
    "mz_tol = 10\n",
    "min_ms1_intensity = 5000\n",
    "ionisation_mode = POSITIVE\n",
    "noise_density = 0.3\n",
    "noise_max_val = 1e4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'chemical_creator': {\n",
    "        'mz_range': mz_range,\n",
    "        'rt_range': rt_range,\n",
    "        'intensity_range': intensity_range,\n",
    "        'n_chemicals': n_chemicals\n",
    "    },\n",
    "    'noise': {\n",
    "        'noise_density': noise_density,\n",
    "        'noise_max_val': noise_max_val,\n",
    "        'mz_range': mz_range\n",
    "    },\n",
    "    'env': {\n",
    "        'ionisation_mode': ionisation_mode,\n",
    "        'rt_range': rt_range,\n",
    "        'N': N,\n",
    "        'isolation_window': isolation_window,\n",
    "        'mz_tol': mz_tol,\n",
    "        'rt_tol': rt_tol,\n",
    "        'min_ms1_intensity': min_ms1_intensity\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_log_level_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = FragmentEnv(params)\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_envs = int(multiprocessing.cpu_count() / 2)\n",
    "n_envs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = make_vec_env(FragmentEnv, n_envs=n_envs, env_kwargs={'params': params})\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"./results/ppo_fragmentenv_tensorboard/\")\n",
    "model.learn(total_timesteps=250000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('results/ppo_all_chems')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load('results/ppo_all_chems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(model, num_episodes):\n",
    "    env = FragmentEnv(params)\n",
    "    total_rewards = []\n",
    "    total_reward_per_chems = []\n",
    "    env_list = []\n",
    "    \n",
    "    for i_episode in range(num_episodes):\n",
    "        observation = env.reset()\n",
    "        total_reward = 0\n",
    "        for t in range(1000):\n",
    "            # env.render()\n",
    "            if model == 'random':\n",
    "                action = env.action_space.sample()\n",
    "                out_file = 'test_%s_%d.mzML' % (model, i_episode)\n",
    "            elif model == 'TopN':\n",
    "                action = -1\n",
    "                out_file = 'test_%s_%d.mzML' % (model, i_episode)                \n",
    "            else:\n",
    "                action, _ = model.predict(observation)     \n",
    "                out_file = 'test_%s_%d.mzML' % ('PPO', i_episode)\n",
    "                                                \n",
    "            observation, reward, done, info = env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                seen_actions = env.seen_actions.most_common()\n",
    "                n_chems = len(env.chems)\n",
    "                reward_per_chems = total_reward / n_chems\n",
    "                print('Episode %d timesteps %d reward %f n_chems %d reward/chems %f actions %s' % (i_episode, t+1, total_reward, n_chems, reward_per_chems, seen_actions))\n",
    "                total_rewards.append(total_reward)\n",
    "                total_reward_per_chems.append(reward_per_chems)\n",
    "                env_list.append(env.vimms_env)\n",
    "                if i_episode % write_mzml_every == 0 or i_episode == num_episodes-1:\n",
    "                    env.vimms_env.write_mzML('results', out_file)\n",
    "                break\n",
    "    env.close()\n",
    "    logger.info('Average total reward = %f' % np.mean(total_rewards))\n",
    "    return np.array(total_rewards), np.array(total_reward_per_chems), env_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100\n",
    "write_mzml_every = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_total_rewards, ppo_reward_per_chems, ppo_env_list = evaluation(model, num_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_total_rewards, random_reward_per_chems, random_env_list = evaluation('random', num_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TopN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topN_total_rewards, topN_reward_per_chems, topN_env_list = evaluation('TopN', num_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_diff(controller_names, scores_list, ref_name, ref_scores):\n",
    "    for controller_name, scores in zip(controller_names, scores_list):\n",
    "        diff = scores - ref_scores\n",
    "        perc = np.multiply(diff, 1/ref_scores) * 100\n",
    "        plt.plot(diff, label=controller_name)\n",
    "    plt.title('Score improvement over %s' % ref_name)\n",
    "    plt.ylabel('Score Improvement (%)')\n",
    "    plt.xlabel('Episode')        \n",
    "    plt.legend()\n",
    "\n",
    "def plot_arr(controller_names, arr_list, title):\n",
    "    for controller_name, arr in zip(controller_names, arr_list):\n",
    "        plt.plot(arr, label=controller_name)\n",
    "    plt.title('%s per Episode' % title)\n",
    "    plt.ylabel(title)\n",
    "    plt.xlabel('Episode')        \n",
    "    plt.legend()\n",
    "        \n",
    "def get_scores(env_list):\n",
    "    scores = []\n",
    "    for env in env_list:\n",
    "        score = get_score(env)\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "def get_score(env):\n",
    "    res = evaluate_simulated_env(env)\n",
    "    score = res['coverage_proportion'] * res['intensity_proportion']\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_arr(['PPO', 'TopN', 'Random'], [ppo_total_rewards, topN_total_rewards, random_total_rewards], 'Total Rewards')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_arr(['PPO', 'TopN', 'Random'], [ppo_reward_per_chems, topN_reward_per_chems, random_reward_per_chems], 'Reward/Chems')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_scores = get_scores(ppo_env_list)\n",
    "topN_scores = get_scores(topN_env_list)\n",
    "random_scores = get_scores(random_env_list)\n",
    "plot_arr(['PPO', 'TopN', 'Random'], [ppo_scores, topN_scores, random_scores], 'Scores')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_diff(['PPO', 'Random'], [ppo_scores, random_scores], 'TopN', topN_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
